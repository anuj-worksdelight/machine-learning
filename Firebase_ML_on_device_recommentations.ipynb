{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Firebase ML on-device recommentations.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "TUfAcER1oUS6",
        "scrolled": true
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gb7qyhNL1yWt"
      },
      "source": [
        "# On-device recommendations with Firebase ML and TensorFlow Lite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fw5Y7snSuG51"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/FirebaseExtended/codelab-contentrecommendation-android/blob/master/Firebase_ML_on_device_recommentations.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/FirebaseExtended/codelab-contentrecommendation-android/blob/master/Firebase_ML_on_device_recommentations.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyYiyNxVp6mS"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CShg7PXmqGUJ"
      },
      "source": [
        "This is the notebook for step 11 of the codelab [**Add recommendations to your app with TensorFlow Lite and Firebase**](https://codelabs.developers.google.com/codelabs/contentrecommendation-android). Before running the code in this notebook, complete steps 1-10 of the codelab to get your app and console projects set up.\n",
        "\n",
        "This code base provides a toolkit to train an on-device recommendation\n",
        "tensorflow model with user data collected in your app with Firebase Analytics. This model will then be deployed with Firebase ML to serve movie recommendations in the sample app FireFlix. \n",
        "\n",
        "This Notebook shows an end-to-end example that 1) imports Firebase Analytics data from BigQuery 2) preprocesses that data to prepare it for training 3) trains a recommendations model using the data and 4) exports the model in tflite format, ready to use in apps to run inference and serve recommendations.\n",
        "\n",
        "Since the app we use in the codelab is just a sample app, it doesn't have the usage necessary to generate a significant amount of analytics events. Since training accurate models requires a large amount of data, for the purposes of this codelab and notebook, we will be simulating a larger analytics event store by using the public [movielens](https://grouplens.org/datasets/movielens/) dataset, but you could\n",
        "adapt the data processing script for your dataset and train your own\n",
        "recommendation model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcLF2PKkSbV3"
      },
      "source": [
        "## Prerequisites\n",
        "\n",
        "Run the cell below to clone the tensorflow recommendations model sample from Github. This is the model we will use, with our analytics training data, to create the recommendations model.\n",
        "\n",
        "The model uses a Convolutional neural-network encoder (CNN): applying multiple layers of convolutional neural-network to generate an encoding of the user history analytics data. For more details, refer to the [documentation]() for the underlying tensorflow model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cv3K3oaksJv",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7855f133-bc92-4cda-ac14-b2f5bca5cc79"
      },
      "source": [
        "!git clone https://github.com/tensorflow/examples\n",
        "%cd /content/examples/lite/examples/recommendation/ml/\n",
        "!pip install -r requirements.txt\n",
        "!pip install --upgrade google-cloud-storage google-cloud-bigquery[bqstorage]"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'examples'...\n",
            "remote: Enumerating objects: 20141, done.\u001b[K\n",
            "remote: Counting objects: 100% (1961/1961), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1060/1060), done.\u001b[K\n",
            "remote: Total 20141 (delta 909), reused 1580 (delta 590), pack-reused 18180\u001b[K\n",
            "Receiving objects: 100% (20141/20141), 33.15 MiB | 27.87 MiB/s, done.\n",
            "Resolving deltas: 100% (11003/11003), done.\n",
            "/content/examples/lite/examples/recommendation/ml\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.1.5)\n",
            "Requirement already satisfied: tensorflow>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (2.7.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (0.12.0)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.5->-r requirements.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.5->-r requirements.txt (line 1)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.5->-r requirements.txt (line 1)) (2018.9)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->-r requirements.txt (line 2)) (1.42.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->-r requirements.txt (line 2)) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->-r requirements.txt (line 2)) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->-r requirements.txt (line 2)) (1.13.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->-r requirements.txt (line 2)) (0.22.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->-r requirements.txt (line 2)) (2.7.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->-r requirements.txt (line 2)) (1.6.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->-r requirements.txt (line 2)) (3.17.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->-r requirements.txt (line 2)) (1.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->-r requirements.txt (line 2)) (0.37.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->-r requirements.txt (line 2)) (3.10.0.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->-r requirements.txt (line 2)) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->-r requirements.txt (line 2)) (3.3.0)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->-r requirements.txt (line 2)) (2.7.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->-r requirements.txt (line 2)) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->-r requirements.txt (line 2)) (2.7.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->-r requirements.txt (line 2)) (12.0.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->-r requirements.txt (line 2)) (2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->-r requirements.txt (line 2)) (3.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.2.0->-r requirements.txt (line 2)) (1.5.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.2.0->-r requirements.txt (line 2)) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.2.0->-r requirements.txt (line 2)) (1.8.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.2.0->-r requirements.txt (line 2)) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.2.0->-r requirements.txt (line 2)) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.2.0->-r requirements.txt (line 2)) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.2.0->-r requirements.txt (line 2)) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.2.0->-r requirements.txt (line 2)) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.2.0->-r requirements.txt (line 2)) (0.4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.2.0->-r requirements.txt (line 2)) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.2.0->-r requirements.txt (line 2)) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.2.0->-r requirements.txt (line 2)) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.2.0->-r requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.2.0->-r requirements.txt (line 2)) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.2.0->-r requirements.txt (line 2)) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.2.0->-r requirements.txt (line 2)) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.2.0->-r requirements.txt (line 2)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.2.0->-r requirements.txt (line 2)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.2.0->-r requirements.txt (line 2)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.2.0->-r requirements.txt (line 2)) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.2.0->-r requirements.txt (line 2)) (3.1.1)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.7/dist-packages (1.18.1)\n",
            "Collecting google-cloud-storage\n",
            "  Downloading google_cloud_storage-1.43.0-py2.py3-none-any.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 5.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-cloud-bigquery[bqstorage] in /usr/local/lib/python3.7/dist-packages (1.21.0)\n",
            "Collecting google-api-core<3.0dev,>=1.29.0\n",
            "  Downloading google_api_core-2.3.2-py2.py3-none-any.whl (109 kB)\n",
            "\u001b[K     |████████████████████████████████| 109 kB 24.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage) (3.17.3)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage) (1.35.0)\n",
            "Collecting google-resumable-media<3.0dev,>=1.3.0\n",
            "  Downloading google_resumable_media-2.1.0-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 2.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage) (2.23.0)\n",
            "Collecting google-cloud-core<3.0dev,>=1.6.0\n",
            "  Downloading google_cloud_core-2.2.1-py2.py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage) (1.15.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0dev,>=1.29.0->google-cloud-storage) (57.4.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0dev,>=1.29.0->google-cloud-storage) (1.53.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (4.8)\n",
            "Collecting google-crc32c<2.0dev,>=1.0\n",
            "  Downloading google_crc32c-1.3.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38 kB)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2021.10.8)\n",
            "Collecting google-cloud-core<3.0dev,>=1.6.0\n",
            "  Downloading google_cloud_core-1.7.2-py2.py3-none-any.whl (28 kB)\n",
            "Collecting google-cloud-bigquery[bqstorage]\n",
            "  Downloading google_cloud_bigquery-2.31.0-py2.py3-none-any.whl (205 kB)\n",
            "\u001b[K     |████████████████████████████████| 205 kB 26.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery[bqstorage]) (2.8.2)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.38.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery[bqstorage]) (1.42.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery[bqstorage]) (21.3)\n",
            "Collecting proto-plus>=1.10.0\n",
            "  Downloading proto_plus-1.19.8-py3-none-any.whl (45 kB)\n",
            "\u001b[K     |████████████████████████████████| 45 kB 3.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow<7.0dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery[bqstorage]) (3.0.0)\n",
            "Collecting google-cloud-bigquery-storage<3.0.0dev,>=2.0.0\n",
            "  Downloading google_cloud_bigquery_storage-2.10.1-py2.py3-none-any.whl (171 kB)\n",
            "\u001b[K     |████████████████████████████████| 171 kB 40.5 MB/s \n",
            "\u001b[?25hCollecting grpcio-status<2.0dev,>=1.33.2\n",
            "  Downloading grpcio_status-1.43.0-py3-none-any.whl (10.0 kB)\n",
            "Collecting libcst>=0.2.5\n",
            "  Downloading libcst-0.3.23-py3-none-any.whl (517 kB)\n",
            "\u001b[K     |████████████████████████████████| 517 kB 41.4 MB/s \n",
            "\u001b[?25hCollecting grpcio<2.0dev,>=1.38.1\n",
            "  Downloading grpcio-1.43.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 40.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.2 in /usr/local/lib/python3.7/dist-packages (from libcst>=0.2.5->google-cloud-bigquery-storage<3.0.0dev,>=2.0.0->google-cloud-bigquery[bqstorage]) (3.10.0.2)\n",
            "Collecting pyyaml>=5.2\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 48.7 MB/s \n",
            "\u001b[?25hCollecting typing-inspect>=0.4.0\n",
            "  Downloading typing_inspect-0.7.1-py3-none-any.whl (8.4 kB)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-cloud-bigquery[bqstorage]) (3.0.6)\n",
            "Collecting protobuf\n",
            "  Downloading protobuf-3.19.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 49.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from pyarrow<7.0dev,>=3.0.0->google-cloud-bigquery[bqstorage]) (1.19.5)\n",
            "Collecting mypy-extensions>=0.3.0\n",
            "  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n",
            "Installing collected packages: protobuf, mypy-extensions, grpcio, typing-inspect, pyyaml, grpcio-status, google-crc32c, google-api-core, proto-plus, libcst, google-resumable-media, google-cloud-core, google-cloud-bigquery-storage, google-cloud-bigquery, google-cloud-storage\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.17.3\n",
            "    Uninstalling protobuf-3.17.3:\n",
            "      Successfully uninstalled protobuf-3.17.3\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.42.0\n",
            "    Uninstalling grpcio-1.42.0:\n",
            "      Successfully uninstalled grpcio-1.42.0\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: google-api-core\n",
            "    Found existing installation: google-api-core 1.26.3\n",
            "    Uninstalling google-api-core-1.26.3:\n",
            "      Successfully uninstalled google-api-core-1.26.3\n",
            "  Attempting uninstall: google-resumable-media\n",
            "    Found existing installation: google-resumable-media 0.4.1\n",
            "    Uninstalling google-resumable-media-0.4.1:\n",
            "      Successfully uninstalled google-resumable-media-0.4.1\n",
            "  Attempting uninstall: google-cloud-core\n",
            "    Found existing installation: google-cloud-core 1.0.3\n",
            "    Uninstalling google-cloud-core-1.0.3:\n",
            "      Successfully uninstalled google-cloud-core-1.0.3\n",
            "  Attempting uninstall: google-cloud-bigquery-storage\n",
            "    Found existing installation: google-cloud-bigquery-storage 1.1.0\n",
            "    Uninstalling google-cloud-bigquery-storage-1.1.0:\n",
            "      Successfully uninstalled google-cloud-bigquery-storage-1.1.0\n",
            "  Attempting uninstall: google-cloud-bigquery\n",
            "    Found existing installation: google-cloud-bigquery 1.21.0\n",
            "    Uninstalling google-cloud-bigquery-1.21.0:\n",
            "      Successfully uninstalled google-cloud-bigquery-1.21.0\n",
            "  Attempting uninstall: google-cloud-storage\n",
            "    Found existing installation: google-cloud-storage 1.18.1\n",
            "    Uninstalling google-cloud-storage-1.18.1:\n",
            "      Successfully uninstalled google-cloud-storage-1.18.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pandas-gbq 0.13.3 requires google-cloud-bigquery[bqstorage,pandas]<2.0.0dev,>=1.11.1, but you have google-cloud-bigquery 2.31.0 which is incompatible.\n",
            "google-cloud-translate 1.5.0 requires google-api-core[grpc]<2.0.0dev,>=1.6.0, but you have google-api-core 2.3.2 which is incompatible.\n",
            "google-cloud-translate 1.5.0 requires google-cloud-core<2.0dev,>=1.0.0, but you have google-cloud-core 2.2.1 which is incompatible.\n",
            "google-cloud-language 1.2.0 requires google-api-core[grpc]<2.0.0dev,>=1.6.0, but you have google-api-core 2.3.2 which is incompatible.\n",
            "google-cloud-firestore 1.7.0 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.3.2 which is incompatible.\n",
            "google-cloud-firestore 1.7.0 requires google-cloud-core<2.0dev,>=1.0.3, but you have google-cloud-core 2.2.1 which is incompatible.\n",
            "google-cloud-datastore 1.8.0 requires google-api-core[grpc]<2.0.0dev,>=1.6.0, but you have google-api-core 2.3.2 which is incompatible.\n",
            "google-cloud-datastore 1.8.0 requires google-cloud-core<2.0dev,>=1.0.0, but you have google-cloud-core 2.2.1 which is incompatible.\n",
            "google-api-python-client 1.12.8 requires google-api-core<2dev,>=1.21.0, but you have google-api-core 2.3.2 which is incompatible.\n",
            "firebase-admin 4.4.0 requires google-api-core[grpc]<2.0.0dev,>=1.14.0; platform_python_implementation != \"PyPy\", but you have google-api-core 2.3.2 which is incompatible.\u001b[0m\n",
            "Successfully installed google-api-core-2.3.2 google-cloud-bigquery-2.31.0 google-cloud-bigquery-storage-2.10.1 google-cloud-core-2.2.1 google-cloud-storage-1.43.0 google-crc32c-1.3.0 google-resumable-media-2.1.0 grpcio-1.43.0 grpcio-status-1.43.0 libcst-0.3.23 mypy-extensions-0.4.3 proto-plus-1.19.8 protobuf-3.19.1 pyyaml-6.0 typing-inspect-0.7.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joSTkeEWN01m"
      },
      "source": [
        "## Set up authentication\n",
        "\n",
        "In this notebook, we use analytics data from BigQuery to generate training data for our recommendations model. To access BigQuery data from the Colab notebook, you need to upload the service account file that you downloaded in step 10 of the codelab.\n",
        "\n",
        "Note: If this step is throwing an error, you can either:\n",
        "1. Manually upload the json file to the /content folder using the Folder icon in the left menu. Then set the GOOGLE_APPLICATION_CREDENTIALS environment variable to the file path.\n",
        "i.e. If file was uploaded to /content, run:\n",
        "`os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]='/content/<your_service_acct_file_name>`\n",
        "OR,\n",
        "2. Try disabling third party cookies in your browser, as [suggested here](https://stackoverflow.com/a/61494336)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqN2Qro5sN5f",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "49e34c46-14aa-4e12-e8ca-ad446de0b6f8"
      },
      "source": [
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "  with open('/content/' + fn, 'wb') as f:\n",
        "    f.write(uploaded[fn])\n",
        "  os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]='/content/' + fn\n",
        "  projectID = fn.rsplit(\"-\", 1)[0]"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-eab65961-ee02-42d1-838f-d70695cdcbf8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-eab65961-ee02-42d1-838f-d70695cdcbf8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving swish-dev-b4614-37d80edbbe33.json to swish-dev-b4614-37d80edbbe33.json\n",
            "User uploaded file \"swish-dev-b4614-37d80edbbe33.json\" with length 2344 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4dy0D_RQK2D"
      },
      "source": [
        "# Import app analytics data from BigQuery\n",
        "\n",
        "In this step, we will load the analytics data we collected in the app with Firebase Analytics and sent to BigQuery. We will load the data into the pandas data processing library and then preprocess this data to be the appropriate format for input for the model training step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUc7uJXMRLNb"
      },
      "source": [
        "## Enable BigQuery IPython magics\n",
        "\n",
        "BigQuery provides several convenience IPython magics that we will use to fetch data with the %load_ext magic below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5J2plSCksN5h"
      },
      "source": [
        "%reload_ext google.cloud.bigquery"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pq46MEB5RlUR"
      },
      "source": [
        "## Import data\n",
        "\n",
        "We use the following SQL statement to get items from the table we created in BigQuery. Firebase Analytics exports a lot of additional information, such as device type, platform version, etc, that we don't need for the purposes of training this model. Initially, we only get a limited amount of rows to briefly explore the form of this data and select which fields are important.\n",
        "\n",
        "Notice that a row in the dataframe is created for each analytics event logged in the app. This row has many properties, but the ones that are of importance for this notebook are the fields:\n",
        "* event_name\n",
        "* event_timestamp\n",
        "* items\n",
        "* user_pseudo_id\n",
        "\n",
        "Notice that some fields, such as the **items** field is actually an object. We will extract the subfield of interest below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoAKLXkZsN5j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a09b6192-821b-4449-9113-5fed64567aa6"
      },
      "source": [
        "%%bigquery analytics_test_import\n",
        "SELECT\n",
        "    *\n",
        "FROM `firebase_recommendations_dataset.recommendations_table`\n",
        "LIMIT 10"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Query complete after 0.07s: 100%|██████████| 1/1 [00:00<00:00, 148.59query/s]\n",
            "Downloading: 100%|██████████| 10/10 [00:01<00:00,  7.91rows/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLXfzEckVMZ1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 826
        },
        "outputId": "0995c85c-87f5-4ad5-9f62-8121eb4666b4"
      },
      "source": [
        "analytics_test_import"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2ceae258-c78a-4c63-b47d-4c5b8d6fcdbe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>provider_id</th>\n",
              "      <th>agency_name</th>\n",
              "      <th>street_address</th>\n",
              "      <th>city</th>\n",
              "      <th>state</th>\n",
              "      <th>zip_code</th>\n",
              "      <th>total_episodes_non_lupa</th>\n",
              "      <th>distinct_users_non_lupa</th>\n",
              "      <th>total_hha_charge_amount_non_lupa</th>\n",
              "      <th>total_hha_medicare_payment_amount_non_lupa</th>\n",
              "      <th>total_hha_medicare_standard_payment_amount_non_lupa</th>\n",
              "      <th>outlier_payments_as_a_percent_of_medicare_payment_amount_non_lupa</th>\n",
              "      <th>total_lupa_episodes</th>\n",
              "      <th>total_hha_medicare_payment_amount_for_lupas</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>337290</td>\n",
              "      <td>AMERICARE CERTIFIED SPECIAL SERVICES, INC CHHA</td>\n",
              "      <td>5923 STRICKLAND AVENUE</td>\n",
              "      <td>BROOKLYN</td>\n",
              "      <td>NY</td>\n",
              "      <td>11234</td>\n",
              "      <td>3148</td>\n",
              "      <td>2310</td>\n",
              "      <td>14112445</td>\n",
              "      <td>12667998</td>\n",
              "      <td>9482140</td>\n",
              "      <td>10</td>\n",
              "      <td>259</td>\n",
              "      <td>108050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>747394</td>\n",
              "      <td>GRANDCARE HOME HEALTH LLC</td>\n",
              "      <td>4701 ARDENWOOD DRIVE</td>\n",
              "      <td>FORT WORTH</td>\n",
              "      <td>TX</td>\n",
              "      <td>76123</td>\n",
              "      <td>773</td>\n",
              "      <td>220</td>\n",
              "      <td>2175373</td>\n",
              "      <td>2016621</td>\n",
              "      <td>1971446</td>\n",
              "      <td>10</td>\n",
              "      <td>30</td>\n",
              "      <td>10111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>17009</td>\n",
              "      <td>ALACARE HOME HEALTH &amp; HOSPICE</td>\n",
              "      <td>2970 LORNA ROAD</td>\n",
              "      <td>BIRMINGHAM</td>\n",
              "      <td>AL</td>\n",
              "      <td>35216</td>\n",
              "      <td>12096</td>\n",
              "      <td>6211</td>\n",
              "      <td>30263356</td>\n",
              "      <td>28901930</td>\n",
              "      <td>35087805</td>\n",
              "      <td>0</td>\n",
              "      <td>1138</td>\n",
              "      <td>320331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>17013</td>\n",
              "      <td>GENTIVA HEALTH SERVICES</td>\n",
              "      <td>557 GLOVER STREET, SUITE 5</td>\n",
              "      <td>ENTERPRISE</td>\n",
              "      <td>AL</td>\n",
              "      <td>36330</td>\n",
              "      <td>809</td>\n",
              "      <td>459</td>\n",
              "      <td>2811738</td>\n",
              "      <td>2224491</td>\n",
              "      <td>2862609</td>\n",
              "      <td>0</td>\n",
              "      <td>54</td>\n",
              "      <td>13475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17014</td>\n",
              "      <td>AMEDISYS HOME HEALTH OF BLOUNTSVILLE</td>\n",
              "      <td>1106 2ND AVENUE E, SUITE E</td>\n",
              "      <td>ONEONTA</td>\n",
              "      <td>AL</td>\n",
              "      <td>35121</td>\n",
              "      <td>463</td>\n",
              "      <td>322</td>\n",
              "      <td>1389586</td>\n",
              "      <td>1188646</td>\n",
              "      <td>1463926</td>\n",
              "      <td>0</td>\n",
              "      <td>59</td>\n",
              "      <td>17068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>17016</td>\n",
              "      <td>SOUTHEAST ALABAMA HOMECARE</td>\n",
              "      <td>804 GLOVER AVENUE</td>\n",
              "      <td>ENTERPRISE</td>\n",
              "      <td>AL</td>\n",
              "      <td>36330</td>\n",
              "      <td>963</td>\n",
              "      <td>502</td>\n",
              "      <td>2842744</td>\n",
              "      <td>2182725</td>\n",
              "      <td>2760829</td>\n",
              "      <td>0</td>\n",
              "      <td>109</td>\n",
              "      <td>29735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>17018</td>\n",
              "      <td>GENTIVA HEALTH SERVICES</td>\n",
              "      <td>3225 RAINBOW STREET, SUITE 256</td>\n",
              "      <td>RAINBOW CITY</td>\n",
              "      <td>AL</td>\n",
              "      <td>35906</td>\n",
              "      <td>2649</td>\n",
              "      <td>1227</td>\n",
              "      <td>8885133</td>\n",
              "      <td>6910206</td>\n",
              "      <td>8699973</td>\n",
              "      <td>0</td>\n",
              "      <td>170</td>\n",
              "      <td>42769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>17020</td>\n",
              "      <td>AMEDISYS HOME HEALTH CARE</td>\n",
              "      <td>273 AZALEA ROAD, SUITE 104, BLDG 2</td>\n",
              "      <td>MOBILE</td>\n",
              "      <td>AL</td>\n",
              "      <td>36609</td>\n",
              "      <td>1028</td>\n",
              "      <td>641</td>\n",
              "      <td>3032311</td>\n",
              "      <td>2512459</td>\n",
              "      <td>3187450</td>\n",
              "      <td>0</td>\n",
              "      <td>126</td>\n",
              "      <td>35139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>17024</td>\n",
              "      <td>SOUTHEAST ALABAMA HOMECARE</td>\n",
              "      <td>810 HEDSTROM DRIVE, SUITE ONE</td>\n",
              "      <td>DOTHAN</td>\n",
              "      <td>AL</td>\n",
              "      <td>36301</td>\n",
              "      <td>2172</td>\n",
              "      <td>1090</td>\n",
              "      <td>6542842</td>\n",
              "      <td>4842608</td>\n",
              "      <td>6141106</td>\n",
              "      <td>0</td>\n",
              "      <td>358</td>\n",
              "      <td>99276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>17025</td>\n",
              "      <td>SAAD HEALTHCARE</td>\n",
              "      <td>1515 UNIVERSITY BLVD, SOUTH</td>\n",
              "      <td>MOBILE</td>\n",
              "      <td>AL</td>\n",
              "      <td>36609</td>\n",
              "      <td>2321</td>\n",
              "      <td>1148</td>\n",
              "      <td>7162296</td>\n",
              "      <td>5876044</td>\n",
              "      <td>7395974</td>\n",
              "      <td>0</td>\n",
              "      <td>206</td>\n",
              "      <td>54841</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ceae258-c78a-4c63-b47d-4c5b8d6fcdbe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2ceae258-c78a-4c63-b47d-4c5b8d6fcdbe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2ceae258-c78a-4c63-b47d-4c5b8d6fcdbe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   provider_id  ... total_hha_medicare_payment_amount_for_lupas\n",
              "0       337290  ...                                      108050\n",
              "1       747394  ...                                       10111\n",
              "2        17009  ...                                      320331\n",
              "3        17013  ...                                       13475\n",
              "4        17014  ...                                       17068\n",
              "5        17016  ...                                       29735\n",
              "6        17018  ...                                       42769\n",
              "7        17020  ...                                       35139\n",
              "8        17024  ...                                       99276\n",
              "9        17025  ...                                       54841\n",
              "\n",
              "[10 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wysL9g8WW5U"
      },
      "source": [
        "All of the columns included in each analytics event entry."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9jHxMTqU8E2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46808d1f-c233-433d-bace-18c10ddf4b1f"
      },
      "source": [
        "analytics_test_import.columns"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['provider_id', 'agency_name', 'street_address', 'city', 'state',\n",
              "       'zip_code', 'total_episodes_non_lupa', 'distinct_users_non_lupa',\n",
              "       'total_hha_charge_amount_non_lupa',\n",
              "       'total_hha_medicare_payment_amount_non_lupa',\n",
              "       'total_hha_medicare_standard_payment_amount_non_lupa',\n",
              "       'outlier_payments_as_a_percent_of_medicare_payment_amount_non_lupa',\n",
              "       'total_lupa_episodes', 'total_hha_medicare_payment_amount_for_lupas'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImvkOzFwWQN4"
      },
      "source": [
        "Of the information logged under 'items', we are only interested in 'item_id',which corresponds to the ID of the movie the user interacted with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVazzlpLVwTN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 826
        },
        "outputId": "807575fc-7e8f-4945-e05e-4a3a475edec9"
      },
      "source": [
        "analytics_test_import"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0fff6f83-43ba-420c-92b3-cdbd3e8a1f6e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>provider_id</th>\n",
              "      <th>agency_name</th>\n",
              "      <th>street_address</th>\n",
              "      <th>city</th>\n",
              "      <th>state</th>\n",
              "      <th>zip_code</th>\n",
              "      <th>total_episodes_non_lupa</th>\n",
              "      <th>distinct_users_non_lupa</th>\n",
              "      <th>total_hha_charge_amount_non_lupa</th>\n",
              "      <th>total_hha_medicare_payment_amount_non_lupa</th>\n",
              "      <th>total_hha_medicare_standard_payment_amount_non_lupa</th>\n",
              "      <th>outlier_payments_as_a_percent_of_medicare_payment_amount_non_lupa</th>\n",
              "      <th>total_lupa_episodes</th>\n",
              "      <th>total_hha_medicare_payment_amount_for_lupas</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>337290</td>\n",
              "      <td>AMERICARE CERTIFIED SPECIAL SERVICES, INC CHHA</td>\n",
              "      <td>5923 STRICKLAND AVENUE</td>\n",
              "      <td>BROOKLYN</td>\n",
              "      <td>NY</td>\n",
              "      <td>11234</td>\n",
              "      <td>3148</td>\n",
              "      <td>2310</td>\n",
              "      <td>14112445</td>\n",
              "      <td>12667998</td>\n",
              "      <td>9482140</td>\n",
              "      <td>10</td>\n",
              "      <td>259</td>\n",
              "      <td>108050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>747394</td>\n",
              "      <td>GRANDCARE HOME HEALTH LLC</td>\n",
              "      <td>4701 ARDENWOOD DRIVE</td>\n",
              "      <td>FORT WORTH</td>\n",
              "      <td>TX</td>\n",
              "      <td>76123</td>\n",
              "      <td>773</td>\n",
              "      <td>220</td>\n",
              "      <td>2175373</td>\n",
              "      <td>2016621</td>\n",
              "      <td>1971446</td>\n",
              "      <td>10</td>\n",
              "      <td>30</td>\n",
              "      <td>10111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>17009</td>\n",
              "      <td>ALACARE HOME HEALTH &amp; HOSPICE</td>\n",
              "      <td>2970 LORNA ROAD</td>\n",
              "      <td>BIRMINGHAM</td>\n",
              "      <td>AL</td>\n",
              "      <td>35216</td>\n",
              "      <td>12096</td>\n",
              "      <td>6211</td>\n",
              "      <td>30263356</td>\n",
              "      <td>28901930</td>\n",
              "      <td>35087805</td>\n",
              "      <td>0</td>\n",
              "      <td>1138</td>\n",
              "      <td>320331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>17013</td>\n",
              "      <td>GENTIVA HEALTH SERVICES</td>\n",
              "      <td>557 GLOVER STREET, SUITE 5</td>\n",
              "      <td>ENTERPRISE</td>\n",
              "      <td>AL</td>\n",
              "      <td>36330</td>\n",
              "      <td>809</td>\n",
              "      <td>459</td>\n",
              "      <td>2811738</td>\n",
              "      <td>2224491</td>\n",
              "      <td>2862609</td>\n",
              "      <td>0</td>\n",
              "      <td>54</td>\n",
              "      <td>13475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17014</td>\n",
              "      <td>AMEDISYS HOME HEALTH OF BLOUNTSVILLE</td>\n",
              "      <td>1106 2ND AVENUE E, SUITE E</td>\n",
              "      <td>ONEONTA</td>\n",
              "      <td>AL</td>\n",
              "      <td>35121</td>\n",
              "      <td>463</td>\n",
              "      <td>322</td>\n",
              "      <td>1389586</td>\n",
              "      <td>1188646</td>\n",
              "      <td>1463926</td>\n",
              "      <td>0</td>\n",
              "      <td>59</td>\n",
              "      <td>17068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>17016</td>\n",
              "      <td>SOUTHEAST ALABAMA HOMECARE</td>\n",
              "      <td>804 GLOVER AVENUE</td>\n",
              "      <td>ENTERPRISE</td>\n",
              "      <td>AL</td>\n",
              "      <td>36330</td>\n",
              "      <td>963</td>\n",
              "      <td>502</td>\n",
              "      <td>2842744</td>\n",
              "      <td>2182725</td>\n",
              "      <td>2760829</td>\n",
              "      <td>0</td>\n",
              "      <td>109</td>\n",
              "      <td>29735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>17018</td>\n",
              "      <td>GENTIVA HEALTH SERVICES</td>\n",
              "      <td>3225 RAINBOW STREET, SUITE 256</td>\n",
              "      <td>RAINBOW CITY</td>\n",
              "      <td>AL</td>\n",
              "      <td>35906</td>\n",
              "      <td>2649</td>\n",
              "      <td>1227</td>\n",
              "      <td>8885133</td>\n",
              "      <td>6910206</td>\n",
              "      <td>8699973</td>\n",
              "      <td>0</td>\n",
              "      <td>170</td>\n",
              "      <td>42769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>17020</td>\n",
              "      <td>AMEDISYS HOME HEALTH CARE</td>\n",
              "      <td>273 AZALEA ROAD, SUITE 104, BLDG 2</td>\n",
              "      <td>MOBILE</td>\n",
              "      <td>AL</td>\n",
              "      <td>36609</td>\n",
              "      <td>1028</td>\n",
              "      <td>641</td>\n",
              "      <td>3032311</td>\n",
              "      <td>2512459</td>\n",
              "      <td>3187450</td>\n",
              "      <td>0</td>\n",
              "      <td>126</td>\n",
              "      <td>35139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>17024</td>\n",
              "      <td>SOUTHEAST ALABAMA HOMECARE</td>\n",
              "      <td>810 HEDSTROM DRIVE, SUITE ONE</td>\n",
              "      <td>DOTHAN</td>\n",
              "      <td>AL</td>\n",
              "      <td>36301</td>\n",
              "      <td>2172</td>\n",
              "      <td>1090</td>\n",
              "      <td>6542842</td>\n",
              "      <td>4842608</td>\n",
              "      <td>6141106</td>\n",
              "      <td>0</td>\n",
              "      <td>358</td>\n",
              "      <td>99276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>17025</td>\n",
              "      <td>SAAD HEALTHCARE</td>\n",
              "      <td>1515 UNIVERSITY BLVD, SOUTH</td>\n",
              "      <td>MOBILE</td>\n",
              "      <td>AL</td>\n",
              "      <td>36609</td>\n",
              "      <td>2321</td>\n",
              "      <td>1148</td>\n",
              "      <td>7162296</td>\n",
              "      <td>5876044</td>\n",
              "      <td>7395974</td>\n",
              "      <td>0</td>\n",
              "      <td>206</td>\n",
              "      <td>54841</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0fff6f83-43ba-420c-92b3-cdbd3e8a1f6e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0fff6f83-43ba-420c-92b3-cdbd3e8a1f6e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0fff6f83-43ba-420c-92b3-cdbd3e8a1f6e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   provider_id  ... total_hha_medicare_payment_amount_for_lupas\n",
              "0       337290  ...                                      108050\n",
              "1       747394  ...                                       10111\n",
              "2        17009  ...                                      320331\n",
              "3        17013  ...                                       13475\n",
              "4        17014  ...                                       17068\n",
              "5        17016  ...                                       29735\n",
              "6        17018  ...                                       42769\n",
              "7        17020  ...                                       35139\n",
              "8        17024  ...                                       99276\n",
              "9        17025  ...                                       54841\n",
              "\n",
              "[10 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF3vnWJXThab"
      },
      "source": [
        "Now we run the following command to import the whole dataset into a variable. Note how we only import the fields which we are interested in for training purposes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXK2PAK5AMpM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9125b57-4534-4878-e706-ea95b7e366a0"
      },
      "source": [
        "%%bigquery analytics_data_real\n",
        "SELECT provider_id, agency_name, street_address, city, zip_code\n",
        "FROM `firebase_recommendations_dataset.recommendations_table`"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Query complete after 0.01s: 100%|██████████| 1/1 [00:00<00:00, 569.57query/s] \n",
            "Downloading: 100%|██████████| 11062/11062 [00:01<00:00, 10648.22rows/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdM67AvOsN5p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "7eb7eb8f-1f18-4e4a-fe8b-6ea388f30a6b"
      },
      "source": [
        "analytics_data_real.head()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f8817a64-584d-4621-a9ac-bf8e142b05b0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>provider_id</th>\n",
              "      <th>agency_name</th>\n",
              "      <th>street_address</th>\n",
              "      <th>city</th>\n",
              "      <th>zip_code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>337290</td>\n",
              "      <td>AMERICARE CERTIFIED SPECIAL SERVICES, INC CHHA</td>\n",
              "      <td>5923 STRICKLAND AVENUE</td>\n",
              "      <td>BROOKLYN</td>\n",
              "      <td>11234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>747394</td>\n",
              "      <td>GRANDCARE HOME HEALTH LLC</td>\n",
              "      <td>4701 ARDENWOOD DRIVE</td>\n",
              "      <td>FORT WORTH</td>\n",
              "      <td>76123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>17009</td>\n",
              "      <td>ALACARE HOME HEALTH &amp; HOSPICE</td>\n",
              "      <td>2970 LORNA ROAD</td>\n",
              "      <td>BIRMINGHAM</td>\n",
              "      <td>35216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>17013</td>\n",
              "      <td>GENTIVA HEALTH SERVICES</td>\n",
              "      <td>557 GLOVER STREET, SUITE 5</td>\n",
              "      <td>ENTERPRISE</td>\n",
              "      <td>36330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17014</td>\n",
              "      <td>AMEDISYS HOME HEALTH OF BLOUNTSVILLE</td>\n",
              "      <td>1106 2ND AVENUE E, SUITE E</td>\n",
              "      <td>ONEONTA</td>\n",
              "      <td>35121</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f8817a64-584d-4621-a9ac-bf8e142b05b0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f8817a64-584d-4621-a9ac-bf8e142b05b0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f8817a64-584d-4621-a9ac-bf8e142b05b0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   provider_id  ... zip_code\n",
              "0       337290  ...    11234\n",
              "1       747394  ...    76123\n",
              "2        17009  ...    35216\n",
              "3        17013  ...    36330\n",
              "4        17014  ...    35121\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTdiPeVjUADI"
      },
      "source": [
        "# Preprocess the dataset\n",
        "\n",
        "In this step, we create a lambda function to extract a subfield 'item_id' from the items object. This represents the movie_id, so we also rename the columns to match."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJzJb0AsDQlk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "outputId": "81de86c1-0d0b-4e65-fb3c-06849b30e876"
      },
      "source": [
        "analytics = analytics_data_real\n",
        "def getAgencyId(row):\n",
        "  items_obj = row['provider_id']\n",
        "  return items_obj\n",
        "analytics['agency_id'] = analytics.apply(lambda row: getAgencyId(row), axis=1)\n",
        "analytics"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a5f9d486-4a29-475b-9542-9e595432fb07\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>provider_id</th>\n",
              "      <th>agency_name</th>\n",
              "      <th>street_address</th>\n",
              "      <th>city</th>\n",
              "      <th>zip_code</th>\n",
              "      <th>agency_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>337290</td>\n",
              "      <td>AMERICARE CERTIFIED SPECIAL SERVICES, INC CHHA</td>\n",
              "      <td>5923 STRICKLAND AVENUE</td>\n",
              "      <td>BROOKLYN</td>\n",
              "      <td>11234</td>\n",
              "      <td>337290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>747394</td>\n",
              "      <td>GRANDCARE HOME HEALTH LLC</td>\n",
              "      <td>4701 ARDENWOOD DRIVE</td>\n",
              "      <td>FORT WORTH</td>\n",
              "      <td>76123</td>\n",
              "      <td>747394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>17009</td>\n",
              "      <td>ALACARE HOME HEALTH &amp; HOSPICE</td>\n",
              "      <td>2970 LORNA ROAD</td>\n",
              "      <td>BIRMINGHAM</td>\n",
              "      <td>35216</td>\n",
              "      <td>17009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>17013</td>\n",
              "      <td>GENTIVA HEALTH SERVICES</td>\n",
              "      <td>557 GLOVER STREET, SUITE 5</td>\n",
              "      <td>ENTERPRISE</td>\n",
              "      <td>36330</td>\n",
              "      <td>17013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17014</td>\n",
              "      <td>AMEDISYS HOME HEALTH OF BLOUNTSVILLE</td>\n",
              "      <td>1106 2ND AVENUE E, SUITE E</td>\n",
              "      <td>ONEONTA</td>\n",
              "      <td>35121</td>\n",
              "      <td>17014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11057</th>\n",
              "      <td>59229</td>\n",
              "      <td>FIFTH AVE HOME HEALTH CARE, INC</td>\n",
              "      <td>5250 SANTA MONICA, SUITE 208 B</td>\n",
              "      <td>LOS ANGELES</td>\n",
              "      <td>90029</td>\n",
              "      <td>59229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11058</th>\n",
              "      <td>557509</td>\n",
              "      <td>APEX HOME HEALTH SERVICES</td>\n",
              "      <td>3919 W SLAUSON AVE</td>\n",
              "      <td>LOS ANGELES</td>\n",
              "      <td>90043</td>\n",
              "      <td>557509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11059</th>\n",
              "      <td>453107</td>\n",
              "      <td>BRITE HEALTH SERVICES LLC</td>\n",
              "      <td>10715 GULFDALE DR SUITE 240</td>\n",
              "      <td>SAN ANTONIO</td>\n",
              "      <td>78216</td>\n",
              "      <td>453107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11060</th>\n",
              "      <td>679667</td>\n",
              "      <td>SOUTHERN ASSURED HOME HEALTH LLC</td>\n",
              "      <td>4211 GARDENDALE DRIVE SUITE A 210</td>\n",
              "      <td>SAN ANTONIO</td>\n",
              "      <td>78229</td>\n",
              "      <td>679667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11061</th>\n",
              "      <td>747360</td>\n",
              "      <td>GMI HOME HEALTH</td>\n",
              "      <td>3503 LURA LANE</td>\n",
              "      <td>SAN ANTONIO</td>\n",
              "      <td>78228</td>\n",
              "      <td>747360</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11062 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a5f9d486-4a29-475b-9542-9e595432fb07')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a5f9d486-4a29-475b-9542-9e595432fb07 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a5f9d486-4a29-475b-9542-9e595432fb07');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       provider_id  ... agency_id\n",
              "0           337290  ...    337290\n",
              "1           747394  ...    747394\n",
              "2            17009  ...     17009\n",
              "3            17013  ...     17013\n",
              "4            17014  ...     17014\n",
              "...            ...  ...       ...\n",
              "11057        59229  ...     59229\n",
              "11058       557509  ...    557509\n",
              "11059       453107  ...    453107\n",
              "11060       679667  ...    679667\n",
              "11061       747360  ...    747360\n",
              "\n",
              "[11062 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXi0XmaJUff6"
      },
      "source": [
        "We drop the 'items' column since we don't need anything else from it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hUZGrBhErs9"
      },
      "source": [
        "analytics.rename(columns={'user_pseudo_id': 'user_id', 'event_timestamp': 'timestamp'}, inplace=True)\n",
        "analytics.drop(['items'], axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQW3-22MUnrH"
      },
      "source": [
        "Here is our processed dataframe containing only the data we want to use in training.\n",
        "\n",
        "The data has the following properties:\n",
        "*   UserIDs range between 1 and 6040\n",
        "*   MovieIDs range between 1 and 3952\n",
        "*   Timestamp is represented in seconds since the epoch as returned by time(2)\n",
        "*   Each user has at least 20 ratings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8S7hp8FFxg6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "outputId": "71cee909-8a52-4994-d575-72a3fe620de6"
      },
      "source": [
        "analytics"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5abc64ce-167a-423c-b5cd-446d65cee29e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>provider_id</th>\n",
              "      <th>agency_name</th>\n",
              "      <th>street_address</th>\n",
              "      <th>city</th>\n",
              "      <th>zip_code</th>\n",
              "      <th>agency_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>337290</td>\n",
              "      <td>AMERICARE CERTIFIED SPECIAL SERVICES, INC CHHA</td>\n",
              "      <td>5923 STRICKLAND AVENUE</td>\n",
              "      <td>BROOKLYN</td>\n",
              "      <td>11234</td>\n",
              "      <td>337290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>747394</td>\n",
              "      <td>GRANDCARE HOME HEALTH LLC</td>\n",
              "      <td>4701 ARDENWOOD DRIVE</td>\n",
              "      <td>FORT WORTH</td>\n",
              "      <td>76123</td>\n",
              "      <td>747394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>17009</td>\n",
              "      <td>ALACARE HOME HEALTH &amp; HOSPICE</td>\n",
              "      <td>2970 LORNA ROAD</td>\n",
              "      <td>BIRMINGHAM</td>\n",
              "      <td>35216</td>\n",
              "      <td>17009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>17013</td>\n",
              "      <td>GENTIVA HEALTH SERVICES</td>\n",
              "      <td>557 GLOVER STREET, SUITE 5</td>\n",
              "      <td>ENTERPRISE</td>\n",
              "      <td>36330</td>\n",
              "      <td>17013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17014</td>\n",
              "      <td>AMEDISYS HOME HEALTH OF BLOUNTSVILLE</td>\n",
              "      <td>1106 2ND AVENUE E, SUITE E</td>\n",
              "      <td>ONEONTA</td>\n",
              "      <td>35121</td>\n",
              "      <td>17014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11057</th>\n",
              "      <td>59229</td>\n",
              "      <td>FIFTH AVE HOME HEALTH CARE, INC</td>\n",
              "      <td>5250 SANTA MONICA, SUITE 208 B</td>\n",
              "      <td>LOS ANGELES</td>\n",
              "      <td>90029</td>\n",
              "      <td>59229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11058</th>\n",
              "      <td>557509</td>\n",
              "      <td>APEX HOME HEALTH SERVICES</td>\n",
              "      <td>3919 W SLAUSON AVE</td>\n",
              "      <td>LOS ANGELES</td>\n",
              "      <td>90043</td>\n",
              "      <td>557509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11059</th>\n",
              "      <td>453107</td>\n",
              "      <td>BRITE HEALTH SERVICES LLC</td>\n",
              "      <td>10715 GULFDALE DR SUITE 240</td>\n",
              "      <td>SAN ANTONIO</td>\n",
              "      <td>78216</td>\n",
              "      <td>453107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11060</th>\n",
              "      <td>679667</td>\n",
              "      <td>SOUTHERN ASSURED HOME HEALTH LLC</td>\n",
              "      <td>4211 GARDENDALE DRIVE SUITE A 210</td>\n",
              "      <td>SAN ANTONIO</td>\n",
              "      <td>78229</td>\n",
              "      <td>679667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11061</th>\n",
              "      <td>747360</td>\n",
              "      <td>GMI HOME HEALTH</td>\n",
              "      <td>3503 LURA LANE</td>\n",
              "      <td>SAN ANTONIO</td>\n",
              "      <td>78228</td>\n",
              "      <td>747360</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11062 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5abc64ce-167a-423c-b5cd-446d65cee29e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5abc64ce-167a-423c-b5cd-446d65cee29e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5abc64ce-167a-423c-b5cd-446d65cee29e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       provider_id  ... agency_id\n",
              "0           337290  ...    337290\n",
              "1           747394  ...    747394\n",
              "2            17009  ...     17009\n",
              "3            17013  ...     17013\n",
              "4            17014  ...     17014\n",
              "...            ...  ...       ...\n",
              "11057        59229  ...     59229\n",
              "11058       557509  ...    557509\n",
              "11059       453107  ...    453107\n",
              "11060       679667  ...    679667\n",
              "11061       747360  ...    747360\n",
              "\n",
              "[11062 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pS2IXA2IW2Xd"
      },
      "source": [
        "## Sort and group training data to create training examples\n",
        "\n",
        "Our analytics events need to be reorganized in the format required for the model training step. We will create an object that maps key user_id to a list of movies that user has seen. We use the timestamp data to create the sequential context."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2gKMD_4sN57"
      },
      "source": [
        "import collections\n",
        "def convert_to_timelines(df):\n",
        "  \"\"\"Convert ratings data to user.\"\"\"\n",
        "  timelines = collections.defaultdict(list)\n",
        "  movie_counts = collections.Counter()\n",
        "  for provider_id, zip_code, agency_id, *_ in df.values:\n",
        "    timelines[provider_id].append([agency_id, zip_code])\n",
        "    movie_counts[agency_id] += 1\n",
        "  # Sort per-user timeline by timestamp\n",
        "  for (provider_id, timeline) in timelines.items():\n",
        "    timeline.sort(key=lambda x: x[1])\n",
        "    timelines[provider_id] = [agency_id for agency_id, _ in timeline]\n",
        "  return timelines, movie_counts\n",
        "timelines, counts = convert_to_timelines(analytics)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0ASLyOYZqCH"
      },
      "source": [
        "The timelines object contains a list of movie_id's keyed on user_id to indicate the sequence of movies that user has interacted with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6Zm23tgsN59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a3d5770-dd49-4da5-9f9a-e35e49f19853"
      },
      "source": [
        "import itertools\n",
        "\n",
        "for key, val in sorted(timelines.items())[0:10]:\n",
        "  print(key, val)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17008 ['2201 ARLINGTON AVENUE']\n",
            "17009 ['2970 LORNA ROAD']\n",
            "17013 ['557 GLOVER STREET, SUITE 5']\n",
            "17014 ['1106 2ND AVENUE E, SUITE E']\n",
            "17016 ['804 GLOVER AVENUE']\n",
            "17017 ['508 ST CLAIR STREET SE']\n",
            "17018 ['3225 RAINBOW STREET, SUITE 256']\n",
            "17020 ['273 AZALEA ROAD, SUITE 104, BLDG 2']\n",
            "17024 ['810 HEDSTROM DRIVE, SUITE ONE']\n",
            "17025 ['1515 UNIVERSITY BLVD, SOUTH']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcxmkcOzZ7Zj"
      },
      "source": [
        "## Generate training examples\n",
        "\n",
        "We use the timelines data to generate tensorflow training examples. We discard any timeline with less than 3 context items, and we consider context lengths of 100 items. We perform the following steps:\n",
        "\n",
        "* Groups movie records by user, and orders per-user movie records by timestamp.\n",
        "* Generates Tensorflow examples with features: 1) \"context\": time-ordered sequential movie IDs 2) \"label\": next movie ID user viewed as label. \"max_history_length\" is taken in as parameter to define \"context\" feature shape, if not enough history found, right padding with out-of-vocab ID 0 will be performed.\n",
        "* Then partition the available data into a training and test set.\n",
        "\n",
        "Sample generated training example with max user history as 10:\n",
        "```\n",
        "0 : {   # (tensorflow.Example)\n",
        "  features: {   # (tensorflow.Features)\n",
        "    feature: {\n",
        "      key  : \"context\"\n",
        "      value: {\n",
        "        int64_list: {\n",
        "          value: [ 595, 2687, 745, 588, 1, 2355, 2294, 783, 1566, 1907 ]\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    feature: {\n",
        "      key  : \"label\"\n",
        "      value: {\n",
        "        int64_list: {\n",
        "          value: [ 48 ]\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwWgd41asN5_"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# used to pad when user doesn't have enough context\n",
        "OOV_MOVIE_ID = 0\n",
        "\n",
        "def generate_examples_from_timelines(timelines,\n",
        "                                     min_timeline_len=3,\n",
        "                                     max_context_len=100):\n",
        "  \"\"\"Convert user timelines to tf examples.\n",
        "\n",
        "  Convert user timelines to tf examples by adding all possible context-label\n",
        "  pairs in the examples pool.\n",
        "\n",
        "  Args:\n",
        "    timelines: the user timelines to process.\n",
        "    min_timeline_len: minimum length of the user timeline.\n",
        "    max_context_len: maximum length of context signals.\n",
        "\n",
        "  Returns:\n",
        "    train_examples: tf example list for training.\n",
        "    test_examples: tf example list for testing.\n",
        "  \"\"\"\n",
        "  train_examples = []\n",
        "  test_examples = []\n",
        "  for timeline in timelines.values():\n",
        "    # Skip if timeline is shorter than min_timeline_len.\n",
        "    if len(timeline) < min_timeline_len:\n",
        "      continue\n",
        "    for label_idx in range(1, len(timeline)):\n",
        "      start_idx = max(0, label_idx - max_context_len)\n",
        "      context = timeline[start_idx:label_idx]\n",
        "      # Pad context with out-of-vocab movie id 0.\n",
        "      while len(context) < max_context_len:\n",
        "        context.append(OOV_MOVIE_ID)\n",
        "      label = timeline[label_idx]\n",
        "      feature = {\n",
        "          \"context\":\n",
        "              tf.train.Feature(int64_list=tf.train.Int64List(value=context)),\n",
        "          \"label\":\n",
        "              tf.train.Feature(int64_list=tf.train.Int64List(value=[label]))\n",
        "      }\n",
        "      tf_example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "      if label_idx == len(timeline) - 1:\n",
        "        test_examples.append(tf_example.SerializeToString())\n",
        "      else:\n",
        "        train_examples.append(tf_example.SerializeToString())\n",
        "  return train_examples, test_examples\n",
        "\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "3v0XcJ3OsN6A"
      },
      "source": [
        "train_examples, test_examples = generate_examples_from_timelines(timelines)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SS4ZYJCjRvO"
      },
      "source": [
        "Write examples to tfrecords, to be loaded in the model training step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVOe4EXUeyjw"
      },
      "source": [
        "def write_tfrecords(tf_examples, filename):\n",
        "  \"\"\"Write tf examples to tfrecord file.\"\"\"\n",
        "  with tf.io.TFRecordWriter(filename) as file_writer:\n",
        "    for example in tf_examples:\n",
        "      file_writer.write(example)\n",
        "\n",
        "output_dir = 'data/examples'\n",
        "OUTPUT_TRAINING_DATA_FILENAME = \"train_movielens_1m.tfrecord\"\n",
        "OUTPUT_TESTING_DATA_FILENAME = \"test_movielens_1m.tfrecord\"\n",
        "\n",
        "if not tf.io.gfile.exists(output_dir):\n",
        "  tf.io.gfile.makedirs(output_dir)\n",
        "write_tfrecords(\n",
        "    tf_examples=train_examples,\n",
        "    filename=os.path.join(output_dir, OUTPUT_TRAINING_DATA_FILENAME))\n",
        "write_tfrecords(\n",
        "    tf_examples=test_examples,\n",
        "    filename=os.path.join(output_dir, OUTPUT_TESTING_DATA_FILENAME))\n",
        "\n",
        "\n"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQcQ6AssuBN8"
      },
      "source": [
        "# Train model\n",
        "\n",
        "The training launcher script uses TensorFlow keras compile/fit APIs and performs\n",
        "the following steps to kick start training and evaluation process:\n",
        "\n",
        "*   Set up both train and eval dataset input function.\n",
        "*   Construct keras model according to provided configs, please refer to sample.config file in the source code to config your model architecture, such as embedding dimension, convolutional neural network params, LSTM units etc.\n",
        "*   Setup loss function. In this code base, we leverages customized batch softmax loss function.\n",
        "*   Setup optimizer, with flag specified learning rate and gradient clip if needed.\n",
        "*   Setup evaluation metrics, we provided recall@k metrics by default.\n",
        "*   Compile model with loss function, optimizer and defined metrics.\n",
        "*   Setup callbacks for tensorboard and checkpoint manager.\n",
        "*   Run model.fit with compiled model, where you could specify number of epochs to train, number of train steps in each epoch and number of eval steps in each epoch.\n",
        "\n",
        "## Model training parameters\n",
        "\n",
        "### Encoder type\n",
        "\n",
        "You can train the model using three different encoder types: a convolutional neural net (cnn), a recurrent neural net (rnn), or a bag of words (bow). You can select between the various types with the **--encoder_type** parameter supplying **cnn**, **rnn**, or **bow**. Different encoders have strengths and weakensses depending on the input / output characteristics of your dataset.\n",
        "\n",
        "For example: If the input context (here, the user history length) is long, cnn and rnn would be more suitable as they have better summarization ability with longer user histories.\n",
        "\n",
        "### Training time / size\n",
        "\n",
        "Another consideration is training time. Rnn generally requires the longer training times, followed by cnn, and finally bow with the shortest training times. Bag of words will also be a smaller sized model if space is a consideration.\n",
        "\n",
        "To start training, execute the following command. Please note that we are using a very small number of epochs (**num_epochs** parameter below) of 10 to speed up training time at the expense of model quality. Generating a high quality model often requires a much higher number. For this model, setting num_epochs to at least 100 should provide a model of sufficient quality. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gPKz5InxEbF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31b93efe-5797-4d54-c530-105af31f5ede"
      },
      "source": [
        "!python -m model.recommendation_model_launcher_keras \\\n",
        "  --run_mode \"train_and_eval\" \\\n",
        "  --encoder_type \"cnn\" \\\n",
        "  --training_data_filepattern \"data/examples/train_movielens_1m.tfrecord\" \\\n",
        "  --testing_data_filepattern \"data/examples/test_movielens_1m.tfrecord\" \\\n",
        "  --model_dir \"model/model_dir\" \\\n",
        "  --params_path \"model/sample_config.json\"\\\n",
        "  --batch_size 64 \\\n",
        "  --learning_rate 0.1 \\\n",
        "  --steps_per_epoch 1000 \\\n",
        "  --num_epochs 10 \\\n",
        "  --num_eval_steps 1000 \\\n",
        "  --gradient_clip_norm 1.0 \\\n",
        "  --max_history_length 10"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/bin/python3: Error while finding module specification for 'model.recommendation_model_launcher_keras' (ModuleNotFoundError: No module named 'model')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObH_mcGcxS96"
      },
      "source": [
        "# Export model\n",
        "\n",
        "Now we export the trained model to a tflite file suitable for on-device inference on mobile devices.\n",
        "Note that here we use the latest checkpoint, number 10000 in the **checkpoint_path**. This results from num_epochs (10) x steps_per_epoch (1000). If you change either parameter in the previous training step, you should update this parameter to accordingly export the latest checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SH5r6AxHzGrS",
        "scrolled": true
      },
      "source": [
        "!python -m model.recommendation_model_launcher_keras \\\n",
        "  --run_mode \"export\" \\\n",
        "  --encoder_type \"cnn\" \\\n",
        "  --params_path \"model/sample_config.json\"\\\n",
        "  --model_dir \"model/model_dir\" \\\n",
        "  --checkpoint_path \"model/model_dir/ckpt-10000\" \\\n",
        "  --num_predictions 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXMQ5D5JzSgv"
      },
      "source": [
        "# Model inference (Optional)\n",
        "\n",
        "You could verify your model's performance by running inference with test examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "og0qkYavz3Nt",
        "scrolled": true
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import json\n",
        "\n",
        "# Use [0, 1, ... 9] as example input to represent 10 movies that user interacted with.\n",
        "#context = [1196, 1210, 2628]\n",
        "# context = tf.range(10)\n",
        "context = tf.constant([1196, 1210, 2628, 260, 480, 2571, 589, 1240, 1, 10])\n",
        "\n",
        "# Directory to exported TensorFlow Lite model.\n",
        "export_dir = \"model/model_dir/export\"\n",
        "tflite_model_path = os.path.join(export_dir, 'model.tflite')\n",
        "f = open(tflite_model_path, 'rb')\n",
        "interpreter = tf.lite.Interpreter(model_content=f.read())\n",
        "interpreter.allocate_tensors()\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "print(input_details)\n",
        "print(output_details)\n",
        "\n",
        "interpreter.set_tensor(input_details[0]['index'], context)\n",
        "interpreter.invoke()\n",
        "tflite_top_predictions_ids = interpreter.get_tensor(\n",
        "    output_details[0]['index'])\n",
        "tflite_top_prediction_scores = interpreter.get_tensor(\n",
        "    output_details[1]['index'])\n",
        "print(\"results >>>>>\")\n",
        "print(\"input >>>>>\")\n",
        "print(input_details[0])\n",
        "print(\"output >>>>>\")\n",
        "print(tflite_top_predictions_ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_omMjoT035u"
      },
      "source": [
        "# Deploy model to the Firebase Console\n",
        "\n",
        "We now deploy the model to the Firebase Console. From there, it can be automatically downloaded to your user's devices with Firebase ML."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awx9Q73aFyfS"
      },
      "source": [
        "Step 1. Initialize Firebase App Instance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxHAv1OaNo-X"
      },
      "source": [
        "import firebase_admin\n",
        "\n",
        "firebase_admin.initialize_app(options={'projectId': projectID, \n",
        "             'storageBucket': projectID + '.appspot.com' })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PxvbLcNNoxZ"
      },
      "source": [
        "Step 2. Upload the model file to Cloud Storage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WPegXrvdnth"
      },
      "source": [
        "from firebase_admin import ml\n",
        "\n",
        "# This uploads it to your bucket as recommendation.tflite\n",
        "source = ml.TFLiteGCSModelSource.from_saved_model(export_dir, 'model.tflite')\n",
        "print (source.gcs_tflite_uri)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjUgFOCCF4Ro"
      },
      "source": [
        "Step 3. Deploy the model to Firebase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbPwOU1iF75O"
      },
      "source": [
        "# Create a Model Format\n",
        "model_format = ml.TFLiteFormat(model_source=source)\n",
        "\n",
        "# Create a Model object\n",
        "sdk_model_1 = ml.Model(display_name=\"recommendations\", model_format=model_format)\n",
        "\n",
        "# Make the Create API call to create the model in Firebase\n",
        "firebase_model_1 = ml.create_model(sdk_model_1)\n",
        "print(firebase_model_1.as_dict())\n",
        "\n",
        "# Publish the model\n",
        "model_id = firebase_model_1.model_id\n",
        "firebase_model_1 = ml.publish_model(model_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvdDw6pXyDIT"
      },
      "source": [
        "# Return to the Firebase Console\n",
        "At this point, we have deployed the trained model to the Firebase console. You can go to Develop > Machine Learning > Custom to check it out!\n",
        "\n",
        "Note that for the purposes of this codelab, in order to have a quick training time, we intentionally chose suboptimal training parameters (as described in the model training step above) that sacrifice model quality. To get better results, please use the pre-trained model included in the Github code repo [here](https://github.com/FirebaseExtended/codelab-contentrecommendation-android/blob/master/recommendation_cnn_i10o100.tflite).\n",
        "To replace the model we just published:\n",
        "1. In the Firebase console, go to Develop > Machine Learning > Custom\n",
        "1. Select the settings dropdown under the model named \"recommendations\"\n",
        "1. Choose \"Replace model\" and upload the model file from the Github repo.\n",
        "\n",
        "Finally, please return to the [codelab](https://codelabs.developers.google.com/codelabs/contentrecommendation-android) and complete the last steps to see the app in action!"
      ]
    }
  ]
}